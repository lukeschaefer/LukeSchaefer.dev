[["Map",1,2,9,10],"meta::meta",["Map",3,4,5,6,7,8],"astro-version","5.1.5","content-config-digest","96b8bf5d7a24a5bc","astro-config-digest","{\"root\":{},\"srcDir\":{},\"publicDir\":{},\"outDir\":{},\"cacheDir\":{},\"site\":\"https://luke.zip/\",\"compressHTML\":true,\"base\":\"/\",\"trailingSlash\":\"ignore\",\"output\":\"static\",\"scopedStyleStrategy\":\"attribute\",\"build\":{\"format\":\"directory\",\"client\":{},\"server\":{},\"assets\":\"_astro\",\"serverEntry\":\"entry.mjs\",\"redirects\":true,\"inlineStylesheets\":\"auto\",\"concurrency\":1},\"server\":{\"open\":false,\"host\":false,\"port\":4321,\"streaming\":true},\"redirects\":{},\"prefetch\":true,\"image\":{\"endpoint\":{\"route\":\"/_image\"},\"service\":{\"entrypoint\":\"astro/assets/services/sharp\",\"config\":{}},\"domains\":[\"webmention.io\"],\"remotePatterns\":[]},\"devToolbar\":{\"enabled\":true},\"markdown\":{\"syntaxHighlight\":false,\"shikiConfig\":{\"langs\":[],\"langAlias\":{},\"theme\":\"github-dark\",\"themes\":{},\"wrap\":false,\"transformers\":[]},\"remarkPlugins\":[null,null,null],\"rehypePlugins\":[null,[null,{\"behavior\":\"wrap\",\"properties\":{\"className\":[\"not-prose\"]}}],[null,{\"rel\":[\"noreferrer\",\"noopener\"],\"target\":\"_blank\"}],null,[null,{\"styleOverrides\":{\"borderRadius\":\"4px\",\"codeFontFamily\":\"iA Writer Mono, SFMono-Regular, Menlo, Monaco, Consolas, \\\"Liberation Mono\\\", \\\"Courier New\\\", monospace;\",\"codeFontSize\":\"0.875rem\",\"codeLineHeight\":\"1.7142857rem\",\"codePaddingInline\":\"1rem\",\"frames\":{\"frameBoxShadowCssValue\":\"none\"},\"uiLineHeight\":\"inherit\"},\"themes\":[\"dracula\",\"github-light\"],\"useThemedScrollbars\":false}]],\"remarkRehype\":{\"footnoteLabelProperties\":{\"className\":[\"\"]}},\"gfm\":true,\"smartypants\":true},\"security\":{\"checkOrigin\":true},\"env\":{\"schema\":{\"WEBMENTION_API_KEY\":{\"context\":\"server\",\"access\":\"secret\",\"optional\":true,\"type\":\"string\"},\"WEBMENTION_URL\":{\"context\":\"client\",\"access\":\"public\",\"optional\":true,\"type\":\"string\"},\"WEBMENTION_PINGBACK\":{\"context\":\"client\",\"access\":\"public\",\"optional\":true,\"type\":\"string\"}},\"validateSecrets\":false},\"experimental\":{\"clientPrerender\":false,\"contentIntellisense\":false,\"responsiveImages\":false},\"legacy\":{\"collections\":false}}","post",["Map",11,12,34,35,65,66,106,107,125,126,143,144,161,162],"hn-zip",{"id":11,"data":13,"body":21,"filePath":22,"digest":23,"rendered":24},{"title":14,"description":15,"draft":16,"tags":17,"publishDate":19,"updatedDate":20},"About HN.zip","This post is an example of how to add a cover/hero image",false,[18],"zip",["Date","2023-11-15T05:00:00.000Z"],["Date","2024-10-01T04:00:00.000Z"],"A year ago I built [hn.zip](https://hn.zip) - a Hacker News proxy site that prioritizes speed over everything else. Jump on it and see how quickly it loads - especially clicking on links.\r\n\r\n---\r\n\r\nThe reason I built the site was simply because I often would browse HN on the NYC Subway - which doesn't have cell connection inside the tunnels. This site aggressively precaches the top 10 comments from the entire front page, so that you can continue to browse, even without internet access.\r\n\r\nIt also takes advantage of PWA Workers so that it can be loaded in complete absense of internet connection, returning whatever data it has cached.\r\n\r\n---\r\n\r\nIt's far from perfect, and not anything I really expect anyone else to use - but it does its job!","src/content/post/hn-zip.md","22ef67096ee26b41",{"html":25,"metadata":26},"\u003Cp>A year ago I built \u003Ca href=\"https://hn.zip\" rel=\"noreferrer noopener\" target=\"_blank\">hn.zip\u003C/a> - a Hacker News proxy site that prioritizes speed over everything else. Jump on it and see how quickly it loads - especially clicking on links.\u003C/p>\n\u003Chr>\n\u003Cp>The reason I built the site was simply because I often would browse HN on the NYC Subway - which doesn’t have cell connection inside the tunnels. This site aggressively precaches the top 10 comments from the entire front page, so that you can continue to browse, even without internet access.\u003C/p>\n\u003Cp>It also takes advantage of PWA Workers so that it can be loaded in complete absense of internet connection, returning whatever data it has cached.\u003C/p>\n\u003Chr>\n\u003Cp>It’s far from perfect, and not anything I really expect anyone else to use - but it does its job!\u003C/p>",{"headings":27,"imagePaths":28,"frontmatter":29},[],[],{"title":14,"description":15,"publishDate":30,"updatedDate":31,"tags":32,"readingTime":33},"15 November 23","01 October 24",[18],"1 min read","making-of-monkeys-2",{"id":34,"data":36,"body":42,"filePath":43,"digest":44,"rendered":45},{"title":37,"description":38,"draft":16,"tags":39,"publishDate":41},"Making of Monkeys.zip (PART TWO)","How monkeys.zip was built",[40],"monkeys",["Date","2025-05-01T00:00:00.000Z"],"If you haven't read [PART ONE](/posts/making-of-monkeys) - take a look, that one goes more into the backend, while this post is a deep-dive specifically into monkey names (I promise it's at least a little interesting).\n\n![Monkeys](/monkeys-hero.png)\n\n## Monkey Names\n\nEvery monkey in [monkeys.zip](https://monkeys.zip) has a unique name, like [Pinzo Dunkins](), or [Luldy Pappington](https://monkeys.zip/m/luldy-pappington). The name generation is simple enough, with a handful of handcrafted prefixes and suffixes that get randomly merged:\n\n![Name Generation](/name_generation.png)\n\nHowever, there's something **much** more special about names. These names aren't just for display purposes, they in fact are the primary unique identifier for monkeys - even **encoding monkey coordinates** into the actual name! This means that:\n\n1) We can have clean monkey-name based URLs, without coordinates\n2) We can load monkey metadata from the name, without needing the backend to respond\n\nSolving this in a satisfactory way took way longer than expected, and the result makes it seem as if zero work went into it, which I guess counts as a success.\n\n### Coordinates --> Monkey Name\n\nWith the above system, we have over 2.7 million available monkey names - more than enough to have no duplicates within a 1024 x 1024 square - outside of this square, we start appending overflow suffixes to the name.\n\nIf we were to naively distribute these monkey names across this square, (EG by incrementing an index and pulling from our name lists) nearby monkeys might have very similar names - **Labobu Tringo** might sit right next to **Labobu Tringson**, and on and on. What we need is a way to (reversably) hash coordinates, so that nearby coordinates have very different results. Here's what I eventually settled on:\n\n![Coordinates to Name](/coordinates-to-name.png)\n\nFirst, we take the X and Y coordinates and convert them both to positive integers. At first I overengineered this, and implemented some sort of spiral encoding, but simply zig-zagging positive and negative numbers was far simpler.\n\nNext, we pack these two 10-bit numbers into a single 20-bit number - then we perform a [Feistal Cipher](https://en.wikipedia.org/wiki/Feistel_cipher) on it. This Cipher was a lifesaver - initial versions of this used my own shooting-from-the-hip code where I mixed the bits up in some predetermined way - but the results were never distributed sufficiently. \n\n:::note\nComing up with a novel solution to this problem is like a very, very low stakes version of rolling your own crypto. As someone who never really otherwise thinks about hashing, prime numbers, and bitwise math, it was extremely fun to play with. But if instead of monkey names, I was hashing passwords, this post would probably be a very sad postmortem.\n:::\n\nHowever, while this encoded result is nicely distributed across the integer space (20 bits) - there was one problem remaining - in that my monkey-name space was actually about *22 bits*. If I naively mapped my encoded result to monkey names, there would be entire prefixes that **never appeared**! I *could* change my name lists so that it exactly fits in 20 bits, but I liked all the names I had.\n\nI'm a little embarrassed how long it took me to figure out what to do here - but after munching on it for a while, the answer was extremely simple:\n\n\u003Ccenter>`const fitResult = (encodedResult * 1572869) % totalCombos;`\u003C/center>\n\nBy using multiplying against a large prime number, we can shuffle our (already nicely distributed) encoded result along the entire space of monkey names. \n\nLastly, we pull from our monkey-name-part arrays based on our final result, and get a name!\n\n### Monkey Name --> Coordinates\n\nSince every step listed above is completely reversible, every step just has to be performed backwards to obtain coordinates from a monkey name! However there was one small mistake that was caught right before launch!\n\n| Prefix | Suffixes |\n| ---    |  ----    |\n| Ba     |  bonky   |\n| Babo   |  rilla   |\n| Na     |  nky     |\n| Pa     |  dson    |\n\nIf these prefixes aren't very carefully curated, names like *Babonky* are ambiguous! Is it `babo-nky` or `ba-bonky`. And of course... making sure monkey names didn't wind up being slurs required careful editing of this table.\n\n-----\n\nPART THREE will be **coming soon**! Here we'll talk more about the frontend, and how we render the monkeys to be (somewhat) performant! Follow me at [@LukeSchaef](https://x.com/LukeSchaef) to see when that's posted.","src/content/post/making-of-monkeys-2.md","f381dcaaf10b49da",{"html":46,"metadata":47},"\u003Cp>If you haven’t read \u003Ca href=\"/posts/making-of-monkeys\">PART ONE\u003C/a> - take a look, that one goes more into the backend, while this post is a deep-dive specifically into monkey names (I promise it’s at least a little interesting).\u003C/p>\n\u003Cimg src=\"/monkeys-hero.png\" alt=\"Monkeys\">\n\u003Ch2 id=\"monkey-names\">\u003Ca class=\"not-prose\" href=\"#monkey-names\">Monkey Names\u003C/a>\u003C/h2>\n\u003Cp>Every monkey in \u003Ca href=\"https://monkeys.zip\" rel=\"noreferrer noopener\" target=\"_blank\">monkeys.zip\u003C/a> has a unique name, like \u003Ca href=\"\">Pinzo Dunkins\u003C/a>, or \u003Ca href=\"https://monkeys.zip/m/luldy-pappington\" rel=\"noreferrer noopener\" target=\"_blank\">Luldy Pappington\u003C/a>. The name generation is simple enough, with a handful of handcrafted prefixes and suffixes that get randomly merged:\u003C/p>\n\u003Cimg src=\"/name_generation.png\" alt=\"Name Generation\">\n\u003Cp>However, there’s something \u003Cstrong>much\u003C/strong> more special about names. These names aren’t just for display purposes, they in fact are the primary unique identifier for monkeys - even \u003Cstrong>encoding monkey coordinates\u003C/strong> into the actual name! This means that:\u003C/p>\n\u003Col>\n\u003Cli>We can have clean monkey-name based URLs, without coordinates\u003C/li>\n\u003Cli>We can load monkey metadata from the name, without needing the backend to respond\u003C/li>\n\u003C/ol>\n\u003Cp>Solving this in a satisfactory way took way longer than expected, and the result makes it seem as if zero work went into it, which I guess counts as a success.\u003C/p>\n\u003Ch3 id=\"coordinates--monkey-name\">\u003Ca class=\"not-prose\" href=\"#coordinates--monkey-name\">Coordinates —> Monkey Name\u003C/a>\u003C/h3>\n\u003Cp>With the above system, we have over 2.7 million available monkey names - more than enough to have no duplicates within a 1024 x 1024 square - outside of this square, we start appending overflow suffixes to the name.\u003C/p>\n\u003Cp>If we were to naively distribute these monkey names across this square, (EG by incrementing an index and pulling from our name lists) nearby monkeys might have very similar names - \u003Cstrong>Labobu Tringo\u003C/strong> might sit right next to \u003Cstrong>Labobu Tringson\u003C/strong>, and on and on. What we need is a way to (reversably) hash coordinates, so that nearby coordinates have very different results. Here’s what I eventually settled on:\u003C/p>\n\u003Cimg src=\"/coordinates-to-name.png\" alt=\"Coordinates to Name\">\n\u003Cp>First, we take the X and Y coordinates and convert them both to positive integers. At first I overengineered this, and implemented some sort of spiral encoding, but simply zig-zagging positive and negative numbers was far simpler.\u003C/p>\n\u003Cp>Next, we pack these two 10-bit numbers into a single 20-bit number - then we perform a \u003Ca href=\"https://en.wikipedia.org/wiki/Feistel_cipher\" rel=\"noreferrer noopener\" target=\"_blank\">Feistal Cipher\u003C/a> on it. This Cipher was a lifesaver - initial versions of this used my own shooting-from-the-hip code where I mixed the bits up in some predetermined way - but the results were never distributed sufficiently.\u003C/p>\n\u003Caside aria-label=\"note\" class=\"admonition\" data-admonition-type=\"note\">\u003Cp class=\"admonition-title\" aria-hidden=\"true\">note\u003C/p>\u003Cdiv class=\"admonition-content\">\u003Cp>Coming up with a novel solution to this problem is like a very, very low stakes version of rolling your own crypto. As someone who never really otherwise thinks about hashing, prime numbers, and bitwise math, it was extremely fun to play with. But if instead of monkey names, I was hashing passwords, this post would probably be a very sad postmortem.\u003C/p>\u003C/div>\u003C/aside>\n\u003Cp>However, while this encoded result is nicely distributed across the integer space (20 bits) - there was one problem remaining - in that my monkey-name space was actually about \u003Cem>22 bits\u003C/em>. If I naively mapped my encoded result to monkey names, there would be entire prefixes that \u003Cstrong>never appeared\u003C/strong>! I \u003Cem>could\u003C/em> change my name lists so that it exactly fits in 20 bits, but I liked all the names I had.\u003C/p>\n\u003Cp>I’m a little embarrassed how long it took me to figure out what to do here - but after munching on it for a while, the answer was extremely simple:\u003C/p>\n\u003Ccenter>`const fitResult = (encodedResult * 1572869) % totalCombos;`\u003C/center>\n\u003Cp>By using multiplying against a large prime number, we can shuffle our (already nicely distributed) encoded result along the entire space of monkey names.\u003C/p>\n\u003Cp>Lastly, we pull from our monkey-name-part arrays based on our final result, and get a name!\u003C/p>\n\u003Ch3 id=\"monkey-name--coordinates\">\u003Ca class=\"not-prose\" href=\"#monkey-name--coordinates\">Monkey Name —> Coordinates\u003C/a>\u003C/h3>\n\u003Cp>Since every step listed above is completely reversible, every step just has to be performed backwards to obtain coordinates from a monkey name! However there was one small mistake that was caught right before launch!\u003C/p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003Ctable>\u003Cthead>\u003Ctr>\u003Cth>Prefix\u003C/th>\u003Cth>Suffixes\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd>Ba\u003C/td>\u003Ctd>bonky\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd>Babo\u003C/td>\u003Ctd>rilla\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd>Na\u003C/td>\u003Ctd>nky\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd>Pa\u003C/td>\u003Ctd>dson\u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\n\u003Cp>If these prefixes aren’t very carefully curated, names like \u003Cem>Babonky\u003C/em> are ambiguous! Is it \u003Ccode>babo-nky\u003C/code> or \u003Ccode>ba-bonky\u003C/code>. And of course… making sure monkey names didn’t wind up being slurs required careful editing of this table.\u003C/p>\n\u003Chr>\n\u003Cp>PART THREE will be \u003Cstrong>coming soon\u003C/strong>! Here we’ll talk more about the frontend, and how we render the monkeys to be (somewhat) performant! Follow me at \u003Ca href=\"https://x.com/LukeSchaef\" rel=\"noreferrer noopener\" target=\"_blank\">@LukeSchaef\u003C/a> to see when that’s posted.\u003C/p>",{"headings":48,"imagePaths":60,"frontmatter":61},[49,53,57],{"depth":50,"slug":51,"text":52},2,"monkey-names","Monkey Names",{"depth":54,"slug":55,"text":56},3,"coordinates--monkey-name","Coordinates —> Monkey Name",{"depth":54,"slug":58,"text":59},"monkey-name--coordinates","Monkey Name —> Coordinates",[],{"title":37,"description":38,"publishDate":62,"tags":63,"readingTime":64},"1 May 25",[40],"4 min read","making-of-monkeys",{"id":65,"data":67,"body":71,"filePath":72,"digest":73,"rendered":74},{"title":68,"description":38,"draft":16,"tags":69,"publishDate":70},"Making of Monkeys.zip (PART ONE)",[40],["Date","2025-05-01T00:00:00.000Z"],"It’s been one month since the [launch](/posts/monkeys-launch) of monkeys.zip. In that time, we’ve gathered over **11,000 monkeys**, which have written over **6 billion words** - completing well over **75%** of the words in Shakespeare's works. In fact, they've [recently finished](https://monkeys.zip/news) writing every four-letter word!\n\n![Monkeys](/monkeys-hero.png)\n\nWhile the initial hype has died down to a small trickle, the monkeys are still typing just as hard as ever, and I figured it'd be a good time to talk about how I built the site. If this part doesn't interest you, check out [PART TWO](/posts/making-of-monkeys-2) where I talk all about the monkey names!\n\n\n## Tech Stack\n\n\n|    |    |\n| --         | --        |\n| Backend & Database:  | **[**Supabase**](https://https://supabase.com/)**   | \n| Frontend Library:       | **[**LitHTML**](https://lit.dev/docs/libraries/standalone-templates/)**    | \n| 3D Library:       |  **[**Three.JS**](https://threejs.org/)**    | \n| Blog:  | **[**Astro**](https://astro.build)**      | \n\n\nThis is a relatively small list of technologies - as I tend to make as much as possible from scratch on my side projects, out of stubbornness. In this project, for example, I made a state management library called [StateFarm](https://github.com/lukeschaefer/StateFarm). It's awful, don't use it.\n\n\n## Simulation Architecture\n\nThe more interesting stuff is how the backend simulation all comes together - it's built as a loosely coupled pipeline with four main steps:\n\n![Monkeys Architecture](/monkeys-architecture.png)\n\n### Ticks \n\nThe first important design decision comes with the concept of **Ticks**. The backend produces data in __15-second long__ batches. The above pipeline runs every 15 seconds, producing 15 seconds worth of monkey-text. This interval length was chosen as a tradeoff between reducing runtime of each step, making errors easier to retry and recover from, and spreading out DB load into smaller chunks, while reducing server \u003C--> client bandwidth and requests.\n\n\n### Step One  (generateTick)\n\nEvery 15 seconds, a cronjob calls a **generateTick** function - which has only one job - which is to put a new tick row in the `ticks` table.\n\n| Tick ID | Start Time | Seed | Status |\n| ----    |   ----     |  --  | ----   |\n| 1234    | 04:13:25   | wn9837xw9873v  | NEW  |\n\nAnd that's all it does! Keeping this step so simple and infallible is crucial to the reliability of later steps. If they fail, or there's a huge data loss, everything can be rebuilt or retried as needed, as long as we have an entry in this table.\n\n### Step Two  (generateTickText)\n\nWhen a new tick is added to this table, the **generateTickText** is called via a WebHook. This function has the job of generating the text for each monkey for that 15-second tick. \n\nWe use [sfc32](https://github.com/bryc/code/blob/master/jshash/PRNGs.md#sfc32) to deterministically generate random numbers based on the seed, which is the tick seed, merged with the monkey seed. This strategy allows a very deterministic random monkey text generator, that can execute both server-side and client-side. \n\n:::note\nI struggled with this for a while, internally debating if I should instead generate the text in a more random way, only on the server. It would feel more philosophically pure for the data to be 'truly' random. The downside of that is increased bandwidth (sending 150 bytes per monkey, vs a 24 byte seed).\n\nTechnically, due to the [pigeon-hole principle](https://en.wikipedia.org/wiki/Pigeonhole_principle), there are far less monkey-tick-seeds than there are 15-second monkey expositions. However, we can work on introducing a greater random space once we expend the existing one (which provides 2^128 states and will last for decades)\n:::\n\nOnce the text is generated, we drop it into a Storage bucket. This isn't strictly necessary, but I like the transparency. For debugging or investigation purposes, it's nice to be able to browse all the text that monkeys have written, without having to regenerate it.\n\n### Step Three (processTick)\n\nWhen the text is dropped into Storage, another WebHook is called, which combs through the text and searches for matches against a dictionary. It builds an immense batch update do a number of Tables in our database\n\n`monkey_words` - Source of truth for every (valid) word every monkey has written\n\n`word_counts_cache` - Faster for lookups of a given word (EG \"monkey\" has appeared 100 times)\n\n`monkey_items`  - Any items a monkey is earned is granted to this table\n\n\n### Step Four (Archive)\n\nA more recent addition has been a separate cleanup script which runs on a cron job - the purpose of which is to archive old, short words from the `monkey_words` table and place them into a `monkey_words_archived` table - which drastically speeds up reads on `monkey_words` (which started slowing down at several billion rows).\n\n---\n\n## Other Backend Things\n\nThe grid of monkeys is labeled into chunks of 64x64 - which hold almost no value, except for creating a minimum query size for monkeys while scrolling through the app - and allowing me to cache these chunks in Redis. During normal traffic, it's actually slower (by over 100 ms) to fetch the cached result from Redis than just query the DB for it - but in the early days when the application was being battered by reddit, it was a lifesaver to be able to render the monkeys without the database needing to be responsive.\n\nThere's still a fair amount of optimization that remains to be done. Now that we're getting into the 'diminishing returns' portion of this project, I'd love to speed the monkey typing up, so that we can start carving through the 6 and 7 letter words, but that will require some further architectural changes. I'm largely considering getting a custom VPS with just a big bucket of RAM, and doing this all in-memory, for speed.\n\n\u003Ca href=\"/posts/making-of-monkeys-2\">\u003Cbutton>PART TWO\u003C/button>\u003C/a>","src/content/post/making-of-monkeys.md","edbacc2b423e0e29",{"html":75,"metadata":76},"\u003Cp>It’s been one month since the \u003Ca href=\"/posts/monkeys-launch\">launch\u003C/a> of monkeys.zip. In that time, we’ve gathered over \u003Cstrong>11,000 monkeys\u003C/strong>, which have written over \u003Cstrong>6 billion words\u003C/strong> - completing well over \u003Cstrong>75%\u003C/strong> of the words in Shakespeare’s works. In fact, they’ve \u003Ca href=\"https://monkeys.zip/news\" rel=\"noreferrer noopener\" target=\"_blank\">recently finished\u003C/a> writing every four-letter word!\u003C/p>\n\u003Cimg src=\"/monkeys-hero.png\" alt=\"Monkeys\">\n\u003Cp>While the initial hype has died down to a small trickle, the monkeys are still typing just as hard as ever, and I figured it’d be a good time to talk about how I built the site. If this part doesn’t interest you, check out \u003Ca href=\"/posts/making-of-monkeys-2\">PART TWO\u003C/a> where I talk all about the monkey names!\u003C/p>\n\u003Ch2 id=\"tech-stack\">\u003Ca class=\"not-prose\" href=\"#tech-stack\">Tech Stack\u003C/a>\u003C/h2>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003Ctable>\u003Cthead>\u003Ctr>\u003Cth>\u003C/th>\u003Cth>\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd>Backend &#x26; Database:\u003C/td>\u003Ctd>\u003Cstrong>\u003Ca href=\"https://https://supabase.com/\" rel=\"noreferrer noopener\" target=\"_blank\">\u003Cstrong>Supabase\u003C/strong>\u003C/a>\u003C/strong>\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd>Frontend Library:\u003C/td>\u003Ctd>\u003Cstrong>\u003Ca href=\"https://lit.dev/docs/libraries/standalone-templates/\" rel=\"noreferrer noopener\" target=\"_blank\">\u003Cstrong>LitHTML\u003C/strong>\u003C/a>\u003C/strong>\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd>3D Library:\u003C/td>\u003Ctd>\u003Cstrong>\u003Ca href=\"https://threejs.org/\" rel=\"noreferrer noopener\" target=\"_blank\">\u003Cstrong>Three.JS\u003C/strong>\u003C/a>\u003C/strong>\u003C/td>\u003C/tr>\u003Ctr>\u003Ctd>Blog:\u003C/td>\u003Ctd>\u003Cstrong>\u003Ca href=\"https://astro.build\" rel=\"noreferrer noopener\" target=\"_blank\">\u003Cstrong>Astro\u003C/strong>\u003C/a>\u003C/strong>\u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\n\u003Cp>This is a relatively small list of technologies - as I tend to make as much as possible from scratch on my side projects, out of stubbornness. In this project, for example, I made a state management library called \u003Ca href=\"https://github.com/lukeschaefer/StateFarm\" rel=\"noreferrer noopener\" target=\"_blank\">StateFarm\u003C/a>. It’s awful, don’t use it.\u003C/p>\n\u003Ch2 id=\"simulation-architecture\">\u003Ca class=\"not-prose\" href=\"#simulation-architecture\">Simulation Architecture\u003C/a>\u003C/h2>\n\u003Cp>The more interesting stuff is how the backend simulation all comes together - it’s built as a loosely coupled pipeline with four main steps:\u003C/p>\n\u003Cimg src=\"/monkeys-architecture.png\" alt=\"Monkeys Architecture\">\n\u003Ch3 id=\"ticks\">\u003Ca class=\"not-prose\" href=\"#ticks\">Ticks\u003C/a>\u003C/h3>\n\u003Cp>The first important design decision comes with the concept of \u003Cstrong>Ticks\u003C/strong>. The backend produces data in \u003Cstrong>15-second long\u003C/strong> batches. The above pipeline runs every 15 seconds, producing 15 seconds worth of monkey-text. This interval length was chosen as a tradeoff between reducing runtime of each step, making errors easier to retry and recover from, and spreading out DB load into smaller chunks, while reducing server &#x3C;—> client bandwidth and requests.\u003C/p>\n\u003Ch3 id=\"step-one--generatetick\">\u003Ca class=\"not-prose\" href=\"#step-one--generatetick\">Step One  (generateTick)\u003C/a>\u003C/h3>\n\u003Cp>Every 15 seconds, a cronjob calls a \u003Cstrong>generateTick\u003C/strong> function - which has only one job - which is to put a new tick row in the \u003Ccode>ticks\u003C/code> table.\u003C/p>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003Ctable>\u003Cthead>\u003Ctr>\u003Cth>Tick ID\u003C/th>\u003Cth>Start Time\u003C/th>\u003Cth>Seed\u003C/th>\u003Cth>Status\u003C/th>\u003C/tr>\u003C/thead>\u003Ctbody>\u003Ctr>\u003Ctd>1234\u003C/td>\u003Ctd>04:13:25\u003C/td>\u003Ctd>wn9837xw9873v\u003C/td>\u003Ctd>NEW\u003C/td>\u003C/tr>\u003C/tbody>\u003C/table>\n\u003Cp>And that’s all it does! Keeping this step so simple and infallible is crucial to the reliability of later steps. If they fail, or there’s a huge data loss, everything can be rebuilt or retried as needed, as long as we have an entry in this table.\u003C/p>\n\u003Ch3 id=\"step-two--generateticktext\">\u003Ca class=\"not-prose\" href=\"#step-two--generateticktext\">Step Two  (generateTickText)\u003C/a>\u003C/h3>\n\u003Cp>When a new tick is added to this table, the \u003Cstrong>generateTickText\u003C/strong> is called via a WebHook. This function has the job of generating the text for each monkey for that 15-second tick.\u003C/p>\n\u003Cp>We use \u003Ca href=\"https://github.com/bryc/code/blob/master/jshash/PRNGs.md#sfc32\" rel=\"noreferrer noopener\" target=\"_blank\">sfc32\u003C/a> to deterministically generate random numbers based on the seed, which is the tick seed, merged with the monkey seed. This strategy allows a very deterministic random monkey text generator, that can execute both server-side and client-side.\u003C/p>\n\u003Caside aria-label=\"note\" class=\"admonition\" data-admonition-type=\"note\">\u003Cp class=\"admonition-title\" aria-hidden=\"true\">note\u003C/p>\u003Cdiv class=\"admonition-content\">\u003Cp>I struggled with this for a while, internally debating if I should instead generate the text in a more random way, only on the server. It would feel more philosophically pure for the data to be ‘truly’ random. The downside of that is increased bandwidth (sending 150 bytes per monkey, vs a 24 byte seed).\u003C/p>\u003Cp>Technically, due to the \u003Ca href=\"https://en.wikipedia.org/wiki/Pigeonhole_principle\" rel=\"noreferrer noopener\" target=\"_blank\">pigeon-hole principle\u003C/a>, there are far less monkey-tick-seeds than there are 15-second monkey expositions. However, we can work on introducing a greater random space once we expend the existing one (which provides 2^128 states and will last for decades)\u003C/p>\u003C/div>\u003C/aside>\n\u003Cp>Once the text is generated, we drop it into a Storage bucket. This isn’t strictly necessary, but I like the transparency. For debugging or investigation purposes, it’s nice to be able to browse all the text that monkeys have written, without having to regenerate it.\u003C/p>\n\u003Ch3 id=\"step-three-processtick\">\u003Ca class=\"not-prose\" href=\"#step-three-processtick\">Step Three (processTick)\u003C/a>\u003C/h3>\n\u003Cp>When the text is dropped into Storage, another WebHook is called, which combs through the text and searches for matches against a dictionary. It builds an immense batch update do a number of Tables in our database\u003C/p>\n\u003Cp>\u003Ccode>monkey_words\u003C/code> - Source of truth for every (valid) word every monkey has written\u003C/p>\n\u003Cp>\u003Ccode>word_counts_cache\u003C/code> - Faster for lookups of a given word (EG “monkey” has appeared 100 times)\u003C/p>\n\u003Cp>\u003Ccode>monkey_items\u003C/code>  - Any items a monkey is earned is granted to this table\u003C/p>\n\u003Ch3 id=\"step-four-archive\">\u003Ca class=\"not-prose\" href=\"#step-four-archive\">Step Four (Archive)\u003C/a>\u003C/h3>\n\u003Cp>A more recent addition has been a separate cleanup script which runs on a cron job - the purpose of which is to archive old, short words from the \u003Ccode>monkey_words\u003C/code> table and place them into a \u003Ccode>monkey_words_archived\u003C/code> table - which drastically speeds up reads on \u003Ccode>monkey_words\u003C/code> (which started slowing down at several billion rows).\u003C/p>\n\u003Chr>\n\u003Ch2 id=\"other-backend-things\">\u003Ca class=\"not-prose\" href=\"#other-backend-things\">Other Backend Things\u003C/a>\u003C/h2>\n\u003Cp>The grid of monkeys is labeled into chunks of 64x64 - which hold almost no value, except for creating a minimum query size for monkeys while scrolling through the app - and allowing me to cache these chunks in Redis. During normal traffic, it’s actually slower (by over 100 ms) to fetch the cached result from Redis than just query the DB for it - but in the early days when the application was being battered by reddit, it was a lifesaver to be able to render the monkeys without the database needing to be responsive.\u003C/p>\n\u003Cp>There’s still a fair amount of optimization that remains to be done. Now that we’re getting into the ‘diminishing returns’ portion of this project, I’d love to speed the monkey typing up, so that we can start carving through the 6 and 7 letter words, but that will require some further architectural changes. I’m largely considering getting a custom VPS with just a big bucket of RAM, and doing this all in-memory, for speed.\u003C/p>\n\u003Cp>\u003Ca href=\"/posts/making-of-monkeys-2\">\u003Cbutton>PART TWO\u003C/button>\u003C/a>\u003C/p>",{"headings":77,"imagePaths":102,"frontmatter":103},[78,81,84,87,90,93,96,99],{"depth":50,"slug":79,"text":80},"tech-stack","Tech Stack",{"depth":50,"slug":82,"text":83},"simulation-architecture","Simulation Architecture",{"depth":54,"slug":85,"text":86},"ticks","Ticks",{"depth":54,"slug":88,"text":89},"step-one--generatetick","Step One  (generateTick)",{"depth":54,"slug":91,"text":92},"step-two--generateticktext","Step Two  (generateTickText)",{"depth":54,"slug":94,"text":95},"step-three-processtick","Step Three (processTick)",{"depth":54,"slug":97,"text":98},"step-four-archive","Step Four (Archive)",{"depth":50,"slug":100,"text":101},"other-backend-things","Other Backend Things",[],{"title":68,"description":38,"publishDate":62,"tags":104,"readingTime":105},[40],"5 min read","monkeys-launch",{"id":106,"data":108,"body":113,"filePath":114,"digest":115,"rendered":116},{"title":109,"description":15,"draft":16,"tags":110,"publishDate":111,"updatedDate":112},"Monkeys.zip launched!",[40],["Date","2025-04-01T00:00:00.000Z"],["Date","2025-05-01T00:00:00.000Z"],"Shortly under a year after leaving Google, and after launching several [smaller](https://hn.zip) [projects](https://deadlock.zip), I'm so excited to announce the launch of [monkeys.zip](https://monkeys.zip)!\n\n![Empty Monkeys](/empty-monkeys.png)\n\u003Ccenter>\u003Ci>Pick a monkey!\u003C/i>\u003C/center>\n\nBased on the [Infinite Monkey Theorem](https://en.wikipedia.org/wiki/Infinite_monkey_theorem), monkeys.zip is a game(?) where users can claim a monkey on the Infinite Grid - this monkey will continually type, as we check each letter written against all the works of Shakespeare! Monkeys are awarded with points and cosmetic items for writing words, while we track the global performance and see how much of Shakespeare's works we can write!\n\nIt has no microtransactions, no ads, no monetization of any form. I originally considered selling monkeys for $5 a pop - but I'd rather have more people enjoy it than try to profit off of such a silly concept.\n\n----\n\n***UPDATE:*** 1 month later, monkeys.zip has over 11,000 monkeys, a (slightly active) [subreddit](https://reddit.com/r/monkeyszip), and has received a lot of love! I've now posted a [making-of](/posts/making-of-monkeys) for the site.","src/content/post/monkeys-launch.md","d41658f7a8074ee3",{"html":117,"metadata":118},"\u003Cp>Shortly under a year after leaving Google, and after launching several \u003Ca href=\"https://hn.zip\" rel=\"noreferrer noopener\" target=\"_blank\">smaller\u003C/a> \u003Ca href=\"https://deadlock.zip\" rel=\"noreferrer noopener\" target=\"_blank\">projects\u003C/a>, I’m so excited to announce the launch of \u003Ca href=\"https://monkeys.zip\" rel=\"noreferrer noopener\" target=\"_blank\">monkeys.zip\u003C/a>!\u003C/p>\n\u003Cimg src=\"/empty-monkeys.png\" alt=\"Empty Monkeys\">\n\u003Ccenter>\u003Ci>Pick a monkey!\u003C/i>\u003C/center>\n\u003Cp>Based on the \u003Ca href=\"https://en.wikipedia.org/wiki/Infinite_monkey_theorem\" rel=\"noreferrer noopener\" target=\"_blank\">Infinite Monkey Theorem\u003C/a>, monkeys.zip is a game(?) where users can claim a monkey on the Infinite Grid - this monkey will continually type, as we check each letter written against all the works of Shakespeare! Monkeys are awarded with points and cosmetic items for writing words, while we track the global performance and see how much of Shakespeare’s works we can write!\u003C/p>\n\u003Cp>It has no microtransactions, no ads, no monetization of any form. I originally considered selling monkeys for $5 a pop - but I’d rather have more people enjoy it than try to profit off of such a silly concept.\u003C/p>\n\u003Chr>\n\u003Cp>\u003Cem>\u003Cstrong>UPDATE:\u003C/strong>\u003C/em> 1 month later, monkeys.zip has over 11,000 monkeys, a (slightly active) \u003Ca href=\"https://reddit.com/r/monkeyszip\" rel=\"noreferrer noopener\" target=\"_blank\">subreddit\u003C/a>, and has received a lot of love! I’ve now posted a \u003Ca href=\"/posts/making-of-monkeys\">making-of\u003C/a> for the site.\u003C/p>",{"headings":119,"imagePaths":120,"frontmatter":121},[],[],{"title":109,"description":15,"publishDate":122,"updatedDate":123,"tags":124,"readingTime":33},"01 April 25","01 May 25",[40],"breathe",{"id":125,"data":127,"body":132,"filePath":133,"digest":134,"rendered":135},{"title":128,"description":15,"draft":16,"tags":129,"publishDate":130,"updatedDate":131},"Breathe.zip",[18],["Date","2025-08-05T04:00:00.000Z"],["Date","2025-08-05T04:00:00.000Z"],"I recently built [breathe.zip](https://breathe.zip) - which is just a simple box breathing app. It uses no JS, only CSS transitions - and is a 20 second loop. In, hold, out, hold, repeat. Should work offline once you load the site once.","src/content/post/breathe.md","25118287931eaca4",{"html":136,"metadata":137},"\u003Cp>I recently built \u003Ca href=\"https://breathe.zip\" rel=\"noreferrer noopener\" target=\"_blank\">breathe.zip\u003C/a> - which is just a simple box breathing app. It uses no JS, only CSS transitions - and is a 20 second loop. In, hold, out, hold, repeat. Should work offline once you load the site once.\u003C/p>",{"headings":138,"imagePaths":139,"frontmatter":140},[],[],{"title":128,"description":15,"publishDate":141,"updatedDate":141,"tags":142,"readingTime":33},"05 August 25",[18],"quicknote",{"id":143,"data":145,"body":150,"filePath":151,"digest":152,"rendered":153},{"title":146,"description":15,"draft":16,"tags":147,"publishDate":148,"updatedDate":149},"quicknote.zip",[18],["Date","2025-09-04T04:00:00.000Z"],["Date","2025-09-04T04:00:00.000Z"],"Today I procrastinated working on my upcoming project and instead made a quick note taking tool, [quicknote.zip](https://quicknote.zip).\r\n\r\nI frequently want to write short notes, a todo list for a day, jot down some thoughts - and often use [doc.new](https://doc.new) which opens a new empty Google Doc. However this is too heavy for most of my needs, takes maybe 2 seconds to fully load and be interactable, and clogs up my google drive with lots of \"Untitled Document\" that just has items like \"buy ham\" in it.\r\n\r\n[quicknote](https://quicknote.zip) loads faster than you can blink, works offline, and gives you a fresh notepad each day, storing to localstorage. That's it, that's all it does.","src/content/post/quicknote.md","35becc5dc2563abf",{"html":154,"metadata":155},"\u003Cp>Today I procrastinated working on my upcoming project and instead made a quick note taking tool, \u003Ca href=\"https://quicknote.zip\" rel=\"noreferrer noopener\" target=\"_blank\">quicknote.zip\u003C/a>.\u003C/p>\n\u003Cp>I frequently want to write short notes, a todo list for a day, jot down some thoughts - and often use \u003Ca href=\"https://doc.new\" rel=\"noreferrer noopener\" target=\"_blank\">doc.new\u003C/a> which opens a new empty Google Doc. However this is too heavy for most of my needs, takes maybe 2 seconds to fully load and be interactable, and clogs up my google drive with lots of “Untitled Document” that just has items like “buy ham” in it.\u003C/p>\n\u003Cp>\u003Ca href=\"https://quicknote.zip\" rel=\"noreferrer noopener\" target=\"_blank\">quicknote\u003C/a> loads faster than you can blink, works offline, and gives you a fresh notepad each day, storing to localstorage. That’s it, that’s all it does.\u003C/p>",{"headings":156,"imagePaths":157,"frontmatter":158},[],[],{"title":146,"description":15,"publishDate":159,"updatedDate":159,"tags":160,"readingTime":33},"04 September 25",[18],"words-zip",{"id":161,"data":163,"body":168,"filePath":169,"digest":170,"rendered":171},{"title":164,"description":15,"draft":16,"tags":165,"publishDate":166,"updatedDate":167},"words.zip",[18],["Date","2026-01-01T05:00:00.000Z"],["Date","2026-01-01T05:00:00.000Z"],"Here is [words.zip](https://words.zip) - and Infinite Word Search that anyone can come participate in.","src/content/post/words-zip.md","5f7430b102259c40",{"html":172,"metadata":173},"\u003Cp>Here is \u003Ca href=\"https://words.zip\" rel=\"noreferrer noopener\" target=\"_blank\">words.zip\u003C/a> - and Infinite Word Search that anyone can come participate in.\u003C/p>",{"headings":174,"imagePaths":175,"frontmatter":176},[],[],{"title":164,"description":15,"publishDate":177,"updatedDate":177,"tags":178,"readingTime":33},"01 January 26",[18]]